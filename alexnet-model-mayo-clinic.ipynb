{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport IPython.display\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom PIL import Image\nfrom glob import glob\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n#!conda install *.tar.bz2 \n#import Pyvips\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\n\n\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\nimport tifffile as tiff\n\nimport cv2\nfrom openslide import OpenSlide\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom pprint import pprint\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport gc\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n#from pytorch_grad_cam.utils.image import show_cam_on_image\n#from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n\n#import timm\n\nfrom torch.cuda.amp import autocast, GradScaler\nImage.MAX_IMAGE_PIXELS = None\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-18T16:32:22.705428Z","iopub.execute_input":"2022-07-18T16:32:22.705857Z","iopub.status.idle":"2022-07-18T16:32:27.669467Z","shell.execute_reply.started":"2022-07-18T16:32:22.705781Z","shell.execute_reply":"2022-07-18T16:32:27.668353Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')\ntrain_data['bilabel'] = np.where(train_data['label']== 'CE', 1, 0)\ntrain, vaild = train_test_split(train_data, test_size=0.2)\n\ntest = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')\nsample_sub = pd.read_csv('../input/mayo-clinic-strip-ai/sample_submission.csv')\npatients_train = train['patient_id'].nunique()\npatients_test = test['patient_id'].nunique()\n#print(test.head())\n#print(f\"Number of unique patients is train set: {patients_train}\")\n#print(f\"Number of unique patients is test set: {patients_test}\")\n#sns.displot(train['label'], stat='percent')\n#plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:32:55.395049Z","iopub.execute_input":"2022-07-18T16:32:55.395977Z","iopub.status.idle":"2022-07-18T16:32:55.441388Z","shell.execute_reply.started":"2022-07-18T16:32:55.395881Z","shell.execute_reply":"2022-07-18T16:32:55.440233Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\"\"\"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:32:56.215329Z","iopub.execute_input":"2022-07-18T16:32:56.217197Z","iopub.status.idle":"2022-07-18T16:32:56.226581Z","shell.execute_reply.started":"2022-07-18T16:32:56.217152Z","shell.execute_reply":"2022-07-18T16:32:56.225559Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'# ====================================================\\n# Utils\\n# ====================================================\\ndef get_score(y_true, y_pred):\\n    score = roc_auc_score(y_true, y_pred)\\n    return score\\n\\n\\ndef init_logger(log_file=OUTPUT_DIR+\\'train.log\\'):\\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\\n    logger = getLogger(__name__)\\n    logger.setLevel(INFO)\\n    handler1 = StreamHandler()\\n    handler1.setFormatter(Formatter(\"%(message)s\"))\\n    handler2 = FileHandler(filename=log_file)\\n    handler2.setFormatter(Formatter(\"%(message)s\"))\\n    logger.addHandler(handler1)\\n    logger.addHandler(handler2)\\n    return logger\\n\\nLOGGER = init_logger()\\n\\n\\ndef seed_torch(seed=42):\\n    random.seed(seed)\\n    os.environ[\\'PYTHONHASHSEED\\'] = str(seed)\\n    np.random.seed(seed)\\n    torch.manual_seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.backends.cudnn.deterministic = True\\n\\nseed_torch(seed=CFG.seed)'"},"metadata":{}}]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, path, df, transform=None):\n        self.df = df\n        self.path = path\n        self.Image_names = df['image_id'].values\n        self.labels = df['bilabel'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # Skip 2c3c06_0.tif as it is too large to read.\n        #if image_id == \"2c3c06_0\":\n         #   continue\n        file_name = self.Image_names[idx]\n        print(file_name)\n        image = tiff.imread(os.path.join(self.path, f\"{file_name}.tif\"))\n        cv2.imwrite(os.path.join(\"./\", f\"{file_name}.jpg\"), image[::scale,::scale,::-1])\n        del image\n        gc.collect()\n        img = Image.open(os.path.join('./', f\"{file_name}.jpg\"))\n        \n        if self.transform:\n            image=self.transform(img)\n        # add another dimension at the front to get NCHW shape\n        #image = img.unsqueeze(0)\n        label = self.labels[idx]\n\n        return image, torch.tensor(label)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:32:56.450470Z","iopub.execute_input":"2022-07-18T16:32:56.450714Z","iopub.status.idle":"2022-07-18T16:32:56.460461Z","shell.execute_reply.started":"2022-07-18T16:32:56.450691Z","shell.execute_reply":"2022-07-18T16:32:56.459127Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"scale = 4\ndata_transform = transforms.Compose([\n        transforms.Resize((256,256)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\ntrain_dataset = TrainDataset(\"../input/mayo-clinic-strip-ai/train\", train, transform = data_transform)\nvaild_dataset = TrainDataset(\"../input/mayo-clinic-strip-ai/train\", vaild, transform = data_transform)\n#test_dataset = TrainDataset(\"../input/mayo-clinic-strip-ai/train\", test, transform = data_transform)\n\ndataset_loader = torch.utils.data.DataLoader(train_dataset,\n                                             batch_size=4, shuffle=True,\n                                             num_workers=0)\ndataset_loader_vaild = torch.utils.data.DataLoader(vaild_dataset,\n                                             batch_size=4, shuffle=True,\n                                             num_workers=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:32:56.614858Z","iopub.execute_input":"2022-07-18T16:32:56.616132Z","iopub.status.idle":"2022-07-18T16:32:56.623894Z","shell.execute_reply.started":"2022-07-18T16:32:56.616094Z","shell.execute_reply":"2022-07-18T16:32:56.622956Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc\n","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:32:56.804725Z","iopub.execute_input":"2022-07-18T16:32:56.805371Z","iopub.status.idle":"2022-07-18T16:32:56.811157Z","shell.execute_reply.started":"2022-07-18T16:32:56.805327Z","shell.execute_reply":"2022-07-18T16:32:56.810124Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class AlexNet(nn.Module):\n    def __init__(self):\n        super(AlexNet, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 96, kernel_size= 11, stride=4, padding=0 )\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride= 1, padding= 2)\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.fc1  = nn.Linear(in_features= 9216, out_features= 4096)\n        self.fc2  = nn.Linear(in_features= 4096, out_features= 4096)\n        self.fc3 = nn.Linear(in_features=4096 , out_features=1)\n\n\n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv2(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.maxpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        x = F.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:32:56.956982Z","iopub.execute_input":"2022-07-18T16:32:56.957229Z","iopub.status.idle":"2022-07-18T16:32:56.969815Z","shell.execute_reply.started":"2022-07-18T16:32:56.957207Z","shell.execute_reply":"2022-07-18T16:32:56.968330Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = AlexNet()\nmodel = model.to(device=device)\nprint(device)\n## Loss and optimizer\nlearning_rate = 1e-4 #I picked this because it seems to be the most used by experts\nload_model = True\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr= learning_rate) #Adam seems to be the most popular for deep learning\nfor epoch in range(5): #I decided to train the model for 5 epochs\n    loss_ep = 0\n    epoch_acc = 0\n    \n    for batch_idx, (data, targets) in enumerate(dataset_loader):\n        data = data.to(device=device)\n        targets = targets.type(torch.FloatTensor).to(device=device)\n        \n        ## Forward Pass\n        optimizer.zero_grad()\n        scores = model(data)\n        loss = criterion(scores.squeeze(),targets)\n        acc = binary_acc(scores.squeeze(),targets)\n        loss.backward()\n        optimizer.step()\n        loss_ep += loss.item()\n        epoch_acc += acc.item()\n        print(batch_idx)\n    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(dataset_loader):.5f} | Acc: {epoch_acc/len(dataset_loader):.3f}')\n\n        \n        \n    with torch.no_grad():\n        num_correct = 0\n        num_samples = 0\n        for batch_idx, (data,targets) in enumerate(dataset_loader_vaild):\n            data = data.to(device=device)\n            targets = targets.to(device=device)\n            ## Forward Pass\n            scores = model(data)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == targets).sum()\n            num_samples += predictions.size(0)\n        print(\n            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n        )\n","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:32:57.098668Z","iopub.execute_input":"2022-07-18T16:32:57.099314Z","iopub.status.idle":"2022-07-18T16:33:07.082576Z","shell.execute_reply.started":"2022-07-18T16:32:57.099270Z","shell.execute_reply":"2022-07-18T16:33:07.079379Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"cuda\n510d2e_0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/390967333.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/1807673401.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{file_name}.tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{file_name}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(files, aszarr, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maszarr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maszarr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTiffSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(self, key, series, level, squeeze, out, maxworkers)\u001b[0m\n\u001b[1;32m   3372\u001b[0m                 )\n\u001b[1;32m   3373\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3374\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3376\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(self, out, squeeze, lock, maxworkers)\u001b[0m\n\u001b[1;32m   6840\u001b[0m                 \u001b[0mmaxworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6841\u001b[0m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6842\u001b[0;31m                 \u001b[0m_fullsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6843\u001b[0m             ):\n\u001b[1;32m   6844\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36msegments\u001b[0;34m(self, lock, maxworkers, func, sort, _fullsize)\u001b[0m\n\u001b[1;32m   6680\u001b[0m                 \u001b[0mflat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6681\u001b[0m             ):\n\u001b[0;32m-> 6682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6684\u001b[0m             \u001b[0;31m# reduce memory overhead by processing chunks of up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(args, decodeargs, keyframe, func)\u001b[0m\n\u001b[1;32m   6668\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecodeargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecodeargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             ):\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecodeargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxworkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmaxworkers\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(data, segmentindex, jpegtables, _fullsize)\u001b[0m\n\u001b[1;32m   6625\u001b[0m                 \u001b[0;31m# TODO: calculate correct size for packed integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6626\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6627\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6628\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6629\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}